{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import TransferConvTime as tct\n",
    "import warnings\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, GlobalAveragePooling1D\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "synthetic_data_path = '../mini synthetic/'\n",
    "saving_model_path = './model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with the simple running for training ConvTime6 on the synthetic data. all we need is to provide the path to the synthetic data and where to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on part 1/12\n",
      "Training sequence length: 100\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Training sequence length: 1000\n",
      "...\n",
      "and so on for all parts and all sequence length\n"
     ]
    }
   ],
   "source": [
    "synthetic_data_path = '../mini synthetic/'\n",
    "saving_model_path = './model/'\n",
    "tct.train_model(synthetic_data_path, saving_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going over the function parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### starting with max_sequence_length - this parameter determans what is the maximum sequence length that the model will be trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on part 1/12\n",
      "Training sequence length: 20\n",
      "Training sequence length: 30\n",
      "...\n",
      "and so on for all parts and all sequence length\n"
     ]
    }
   ],
   "source": [
    "tct.train_model(synthetic_data_path, saving_model_path, max_sequence_length=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we can see, only sequence length that is smaller than 40 were trained...\n"
     ]
    }
   ],
   "source": [
    "print(\"As we can see, only sequence length that is smaller than 40 were trained...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moving on with model - this parameter determans which model to train. default is \"ConvTime6\" from our paper, however you can provide any model you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, None, 100)         200       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 55)                5555      \n",
      "=================================================================\n",
      "Total params: 5,755\n",
      "Trainable params: 5,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(Dense(100,activation=\"relu\",input_shape=(None,1)))\n",
    "my_model.add(GlobalAveragePooling1D())\n",
    "my_model.add(Dense(55,activation=\"linear\"))\n",
    "my_model.compile(loss='MSE',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['mse'])\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on part 1/12\n",
      "Training sequence length: 100\n",
      "Training sequence length: 1000\n",
      "...\n",
      "and so on for all parts and all sequence length\n"
     ]
    }
   ],
   "source": [
    "tct.train_model(synthetic_data_path, saving_model_path, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we can see the new model is trained...\n",
      "important thing: don't forget to customize the last layer so it will fit the synthetic data.\n",
      "In our paper, we used 55 linear, so if you are using our synthetic data, don't forget to set last layer\n"
     ]
    }
   ],
   "source": [
    "print(\"As we can see the new model is trained...\")\n",
    "print(\"important thing: don't forget to customize the last layer so it will fit the synthetic data.\")\n",
    "print(\"In our paper, we used 55 linear, so if you are using our synthetic data, don't forget to set last layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moving on with save each file - this parameter determans whether to save model after each file. default is True, let's look at False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently we have 2 checkpoints models:\n",
      "['model_1.json', 'model_2.json', 'weight_1.h5', 'weight_2.h5']\n",
      "Now let's train a new model with only saving the final model\n"
     ]
    }
   ],
   "source": [
    "print(\"Currently we have 2 checkpoints models:\")\n",
    "print(os.listdir(\"./model\"))\n",
    "print(\"Now let's train a new model with only saving the final model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on part 1/12\n",
      "Training sequence length: 100\n",
      "Training sequence length: 1000\n",
      "...\n",
      "and so on for all parts and all sequence length\n"
     ]
    }
   ],
   "source": [
    "tct.train_model(synthetic_data_path, saving_model_path, model=my_model, save_each_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently we have 2 checkpoints models and one final mode:\n",
      "['model_1.json', 'model_2.json', 'model_final2.json', 'weight_1.h5', 'weight_2.h5', 'weight_final2.h5']\n",
      "We can see that final model were added to the files. the number after the final represent the number of files that model was trained on before finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Currently we have 2 checkpoints models and one final mode:\")\n",
    "print(os.listdir(\"./model\"))\n",
    "print(\"We can see that final model were added to the files. the number after the final represent the number of files that model was trained on before finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moving on with start counter - if you used \"save each file\" to be True (as default), and training crashed after let's say 2 files, we want to continue from that point. so we will set our start_counter to be 2, and let the model continue from there. \n",
    "#### What we do is load the model using the start_counter checkpoint, and continue training from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Currently on part 1/12\n",
      "Training sequence length: 120\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Training sequence length: 1200\n",
      "...\n",
      "and so on for all parts and all sequence length\n"
     ]
    }
   ],
   "source": [
    "tct.train_model(synthetic_data_path, saving_model_path, start_counter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently we have 2 new checkpoints: (3,4)\n",
      "\n",
      "['model_1.json', 'model_2.json', 'model_3.json', 'model_4.json', 'model_final2.json', 'model_final4.json', 'weight_1.h5', 'weight_2.h5', 'weight_3.h5', 'weight_4.h5', 'weight_final2.h5', 'weight_final4.h5']\n",
      "\n",
      "We can see as well, that we start from sequence length 120 (which is file #3) and not from 100 (file #1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Currently we have 2 new checkpoints: (3,4)\")\n",
    "print()\n",
    "print(os.listdir(\"./model\"))\n",
    "print()\n",
    "print(\"We can see as well, that we start from sequence length 120 (which is file #3) and not from 100 (file #1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's it! simple as that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feel free to contact me at rotemyar@post.bgu.ac.il\n"
     ]
    }
   ],
   "source": [
    "print(\"Feel free to contact me at rotemyar@post.bgu.ac.il\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
